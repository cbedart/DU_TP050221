{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du jeu de données\n",
    "\n",
    "L'exécution de ce notebook est parfaitement optionnelle, les données étant fournies préparées.<br/>\n",
    "On le met à disposition pour la simple curiosité des étudiant·e·s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation manuelle\n",
    "\n",
    "On commence par télécharger les données [ici](http://ai.stanford.edu/%7Eamaas/data/sentiment/) (Large Movie Review Dataset v1.0) et par décompresser l'archive (avec tar soux Linux, ou 7Zip sous Windows) afin d'en extraire le contenu dans un dossier donné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture des données\n",
    "\n",
    "On va lire les données pour constituer un unique DataFrame contenant le corpus d'entraînement, et un second pour le test.\n",
    "\n",
    "Dans un premier temps on définit les fonctions nécessaires à lire un fichier, puis à charger tout un sous-corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # standard library module\n",
    "import re  # standard library module\n",
    "\n",
    "import pandas as pd  # third-party module (`pip install pandas`)\n",
    "\n",
    "\n",
    "def read_rating_file(path):\n",
    "    \"\"\"Read a given movie review file.\n",
    "    \n",
    "    Return both the review itself (str) and the associated rate (int).\n",
    "    \"\"\"\n",
    "    # Parse file name to get the review's rate (format: 'id_rate.txt').\n",
    "    name = os.path.basename(path)[:-4]\n",
    "    rate = int(name.rsplit('_', 1)[1])\n",
    "    # Read the file's content, remove trailing whitespaces.\n",
    "    with open(path, mode='r', encoding='utf-8') as file:\n",
    "        text = file.read().strip('\\n')\n",
    "    # Run minimal normalization on separation characters.\n",
    "    text = re.sub('<br ?/>', ' ', text)  # remove html linebreaks\n",
    "    text = re.sub(r'[\\n\\t]', ' ', text)  # remove linebreaks and tabs\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)   # remove redundant whitespaces\n",
    "    # Return the text and the rate.\n",
    "    return (text, rate)\n",
    "\n",
    "\n",
    "def load_imdb_subset(path):\n",
    "    \"\"\"Load all samples from either the train of test IMDB review dataset.\n",
    "    \n",
    "    path : path to either the 'train' or 'test' folder in the IMDB dataset\n",
    "           initial uncompressed export\n",
    "           \n",
    "    Return a pd.DataFrame storing reviews, with both their 'text', 'rate'\n",
    "    and 'polarity'.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for folder in ('neg', 'pos'):\n",
    "        folder = os.path.join(path, folder)\n",
    "        for file in sorted(os.listdir(folder)):\n",
    "            text, rate = read_rating_file(os.path.join(folder, file))\n",
    "            samples.append({'text': text, 'rate': rate, 'polarity': int(rate >= 7)})\n",
    "    return pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on utilise ces fonctions pour charger les deux DataFrames pandas.\n",
    "On en profite pour visualiser les premières lignes du jeu \"train\" et les dimensions des deux jeux (250k reviews par jeu, avec une égalité parfaite positif/négatif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two subdatasets (this can take a bit of time).\n",
    "train = load_imdb_subset('./imdb/train')\n",
    "test = load_imdb_subset('./imdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first lines of the train set (display cut text).\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shapes of the DataFrames.\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the share of positive (>= 7) reviews in each subset.\n",
    "print(train['polarity'].mean())\n",
    "print(test['polarity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of reviews per exact rate in the train set.\n",
    "print(train['rate'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données\n",
    "\n",
    "On pourraît s'arrêter là, mais on va plutôt :\n",
    "* faire un petit peu de normalisation en plus pour se faciliter la vie ensuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack both subsets into a single DataFrame.\n",
    "data = pd.concat([train, test], axis=0)\n",
    "data.index = list(range(len(data)))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove non-informative unicode characters (things such as '\\x8d').\n",
    "import unicodedata  # third-party module (`pip install unicodedata`)\n",
    "\n",
    "def remove_noncharacters(text):\n",
    "    \"\"\"Remove unicode 'other' characters from a text.\"\"\"\n",
    "    return ''.join(\n",
    "        char for char in unicodedata.normalize('NFD', text)\n",
    "        if not unicodedata.category(char).startswith('C')\n",
    "    )\n",
    "\n",
    "data['text'] = data['text'].apply(remove_noncharacters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: On garde les accents, qui semblent utilisés avec parcimonie (noms propres et emprunts au Français, e.g. \"cliché\") et donc convoyer une information pertinente. De même, on laisse à ce stade toute la ponctuation, y compris des symboles qui n'ont probablement aucun sens pris seuls (e.g. pas dans un n-gram ou dans un modèle faisant un usage séquentiel du texte)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* produire un nouveau split train / validation / test avec des proportions 70% / 15% / 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # third-party library, dependency of pandas\n",
    "\n",
    "# Set up a Random Number Generator; use a seed for reproducibility.\n",
    "rng = np.random.Generator(np.random.MT19937(seed=0))\n",
    "# Randomly split the dataset in disjoint subsets.\n",
    "idx = data.index.values  # copy the dataset's index\n",
    "rng.shuffle(idx)         # randomly shuffle this copy\n",
    "train = data.loc[idx[:35000]]       # 70% of samples\n",
    "valid = data.loc[idx[35000:42500]]  # 15% of samples\n",
    "test = data.loc[idx[42500:]]        # 15% of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export des données\n",
    "\n",
    "Finalement, on exporte les trois jeux de données au format tsv (tab-separated value).\n",
    "\n",
    "_Note: on utilise la tabulation plutôt que la virgule (standard csv, comma-separated value) car les textes contiennent des virgules ; on s'évite ainsi d'éventuels problèmes de parseur._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the output data folder if needed.\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "# Write down tsv files.\n",
    "train.to_csv('./data/train.tsv', sep='\\t', index=False)\n",
    "valid.to_csv('./data/valid.tsv', sep='\\t', index=False)\n",
    "test.to_csv('./data/test.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
